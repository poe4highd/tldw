import os
import sys
import sqlite3
import yt_dlp
import whisper
import openai
import json
import re
from datetime import datetime

class VideoProcessor:
    def __init__(self, database):
        self.db = database
        self.whisper_model = None
        self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
        self.log_messages = []  # å­˜å‚¨è¯¦ç»†æ—¥å¿—æ¶ˆæ¯
        self.device = None  # ç¼“å­˜è®¾å¤‡ä¿¡æ¯
        
        # Whisperæ¨¡å‹ä¼˜å…ˆçº§ (æ•°å€¼è¶Šé«˜ä¼˜å…ˆçº§è¶Šé«˜)
        self.model_priority = {
            'tiny': 1,
            'base': 2,
            'small': 3,
            'medium': 4,
            'large': 5,
            'large-v2': 6,
            'large-v3': 7
        }
    
    def log(self, message):
        """æ·»åŠ æ—¥å¿—æ¶ˆæ¯"""
        print(message)  # æœåŠ¡å™¨ç«¯æ—¥å¿—
        self.log_messages.append(message)  # æ”¶é›†ç”¨äºå‰ç«¯æ˜¾ç¤º
    
    def get_logs(self):
        """è·å–æ”¶é›†çš„æ—¥å¿—"""
        return '\n'.join(self.log_messages)
    
    def clear_logs(self):
        """æ¸…é™¤æ—¥å¿—"""
        self.log_messages = []
    
    def get_optimal_device(self):
        """è·å–æœ€ä¼˜è®¾å¤‡é…ç½®"""
        if self.device is None:
            import torch
            
            if torch.cuda.is_available():
                # æ£€æŸ¥GPUå†…å­˜
                gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3  # GB
                self.device = {
                    'type': 'cuda',
                    'name': torch.cuda.get_device_name(0),
                    'memory': f"{gpu_memory:.1f}GB",
                    'optimal_model': 'medium' if gpu_memory > 4 else 'base'
                }
                self.log(f"ğŸ® æ£€æµ‹åˆ°GPU: {self.device['name']} ({self.device['memory']})")
            else:
                # CPUé…ç½®
                import psutil
                cpu_count = psutil.cpu_count()
                memory_gb = psutil.virtual_memory().total / 1024**3
                self.device = {
                    'type': 'cpu',
                    'name': f"{cpu_count}æ ¸CPU",
                    'memory': f"{memory_gb:.1f}GB",
                    'optimal_model': 'tiny' if memory_gb < 8 else 'base'
                }
                self.log(f"ğŸ’» ä½¿ç”¨CPU: {self.device['name']} ({self.device['memory']})")
        
        return self.device
    
    def extract_video_id(self, youtube_url):
        """ä»YouTube URLæå–è§†é¢‘ID"""
        # æ”¯æŒå¤šç§YouTube URLæ ¼å¼
        patterns = [
            r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([^&\n?#]+)',
            r'youtube\.com/watch\?.*v=([^&\n?#]+)'
        ]
        
        for pattern in patterns:
            match = re.search(pattern, youtube_url)
            if match:
                video_id = match.group(1)
                # YouTubeè§†é¢‘IDé€šå¸¸æ˜¯11ä¸ªå­—ç¬¦
                if len(video_id) == 11:
                    return video_id
        
        # å¦‚æœæ— æ³•æå–ï¼ŒæŠ›å‡ºå¼‚å¸¸
        raise ValueError(f"æ— æ³•ä»URLæå–è§†é¢‘ID: {youtube_url}")
    
    def load_whisper_model(self):
        """å»¶è¿ŸåŠ è½½Whisperæ¨¡å‹ - æ™ºèƒ½é€‰æ‹©æ¨¡å‹å’Œè®¾å¤‡"""
        if self.whisper_model is None:
            # è·å–æœ€ä¼˜è®¾å¤‡é…ç½®
            device_info = self.get_optimal_device()
            device = device_info['type']
            model_name = device_info['optimal_model']
            
            self.log(f"ğŸ¤– Loading Whisper {model_name} model on {device}...")
            self.log(f"ğŸ“Š ç¡¬ä»¶é…ç½®: {device_info['name']} ({device_info['memory']})")
            
            try:
                # åŠ è½½æ¨¡å‹æ—¶æ·»åŠ æ›´å¤šé…ç½®
                if device == "cuda":
                    import torch
                    # æ¸…ç†GPUå†…å­˜
                    if torch.cuda.is_available():
                        torch.cuda.empty_cache()
                    
                self.whisper_model = whisper.load_model(model_name, device=device)
                self.log(f"âœ… Whisper {model_name} æ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: {device})")
                
                # æ˜¾ç¤ºæ¨¡å‹ä¿¡æ¯
                model_params = sum(p.numel() for p in self.whisper_model.parameters()) / 1e6
                self.log(f"ğŸ“Š æ¨¡å‹å‚æ•°é‡: {model_params:.1f}M")
                
            except Exception as e:
                # å¦‚æœé¦–é€‰æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°æœ€å°æ¨¡å‹
                self.log(f"âš ï¸ {model_name}æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå›é€€åˆ°tinyæ¨¡å‹: {str(e)}")
                try:
                    self.whisper_model = whisper.load_model("tiny", device="cpu")
                    self.log("âœ… Whisper tinyæ¨¡å‹åŠ è½½å®Œæˆ (è®¾å¤‡: CPU)")
                except Exception as fallback_error:
                    raise Exception(f"Whisperæ¨¡å‹åŠ è½½å®Œå…¨å¤±è´¥: {str(fallback_error)}")
                
        return self.whisper_model
    
    def should_reanalyze_with_better_model(self, video_id, current_model):
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹é‡æ–°åˆ†æ"""
        # è·å–è¯¥è§†é¢‘ä¹‹å‰ä½¿ç”¨çš„æ¨¡å‹
        previous_model = self.db.get_video_whisper_model(video_id)
        
        if not previous_model:
            # é¦–æ¬¡åˆ†æï¼Œè®°å½•å½“å‰æ¨¡å‹
            self.db.update_whisper_model(video_id, current_model)
            return False, None
        
        # æ¯”è¾ƒæ¨¡å‹ä¼˜å…ˆçº§
        current_priority = self.model_priority.get(current_model, 0)
        previous_priority = self.model_priority.get(previous_model, 0)
        
        if current_priority > previous_priority:
            self.log(f"ğŸ”„ æ£€æµ‹åˆ°æ¨¡å‹å‡çº§: {previous_model} â†’ {current_model}")
            self.log(f"ğŸ“ˆ æ¨¡å‹ä¼˜å…ˆçº§æå‡: {previous_priority} â†’ {current_priority}")
            return True, previous_model
        
        return False, previous_model
    
    def get_current_optimal_model(self):
        """è·å–å½“å‰ç¯å¢ƒä¸‹çš„æœ€ä¼˜æ¨¡å‹"""
        device_info = self.get_optimal_device()
        return device_info['optimal_model']
    
    def download_audio_fallback(self, youtube_url, video_id):
        """å¤‡ç”¨ä¸‹è½½æ–¹æ³• - ä½¿ç”¨æœ€ç®€é…ç½®"""
        strategies = [
            # ç­–ç•¥1: ä½¿ç”¨Androidå®¢æˆ·ç«¯
            {
                'format': 'bestaudio/best',
                'outtmpl': f'downloads/%(title)s.%(ext)s',
                'extractor_args': {'youtube': {'player_client': ['android']}},
                'user_agent': 'com.google.android.youtube/17.31.35 (Linux; U; Android 11) gzip',
            },
            # ç­–ç•¥2: ä½¿ç”¨iOSå®¢æˆ·ç«¯
            {
                'format': 'bestaudio/best', 
                'outtmpl': f'downloads/%(title)s.%(ext)s',
                'extractor_args': {'youtube': {'player_client': ['ios']}},
                'user_agent': 'com.google.ios.youtube/17.31.4 (iPhone; CPU iPhone OS 15_6 like Mac OS X)',
            },
            # ç­–ç•¥3: æœ€åŸºæœ¬é…ç½®
            {
                'format': 'worst[ext=webm]/worst',
                'outtmpl': f'downloads/%(title)s.%(ext)s',
                'no_warnings': True,
                'quiet': True,
            }
        ]
        
        for i, ydl_opts in enumerate(strategies, 1):
            try:
                self.log(f"ğŸ“± å°è¯•å¤‡ç”¨ç­–ç•¥ {i}...")
                with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                    info = ydl.extract_info(youtube_url, download=False)
                    video_title = info.get('title', 'Unknown Title')
                    
                    # æ›´æ–°æ•°æ®åº“ä¸­çš„è§†é¢‘æ ‡é¢˜
                    with sqlite3.connect(self.db.db_path) as conn:
                        cursor = conn.cursor()
                        cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                        conn.commit()
                    
                    # ä¸‹è½½éŸ³é¢‘
                    ydl.download([youtube_url])
                    
                    # æ‰¾åˆ°ä¸‹è½½çš„æ–‡ä»¶
                    safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    # æ£€æŸ¥å¯èƒ½çš„æ–‡ä»¶æ ¼å¼
                    for ext in ['.webm', '.mp4', '.m4a', '.mp3']:
                        audio_file = f"downloads/{safe_title}{ext}"
                        if os.path.exists(audio_file):
                            return audio_file, video_title
                    
                    raise Exception("æ‰¾ä¸åˆ°ä¸‹è½½çš„éŸ³é¢‘æ–‡ä»¶")
                    
            except Exception as e:
                self.log(f"âŒ å¤‡ç”¨ç­–ç•¥ {i} å¤±è´¥: {str(e)}")
                continue
        
        raise Exception("æ‰€æœ‰å¤‡ç”¨ç­–ç•¥éƒ½å¤±è´¥äº†")

    def download_audio_final_fallback(self, youtube_url, video_id):
        """æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆ - å¤åˆ¶æµ‹è¯•è„šæœ¬çš„ç¡®åˆ‡é…ç½®"""
        try:
            self.log("ğŸ¯ ä½¿ç”¨æµ‹è¯•è„šæœ¬éªŒè¯çš„ç¡®åˆ‡é…ç½®...")
            
            # å®Œå…¨å¤åˆ¶æµ‹è¯•è„šæœ¬ä¸­æˆåŠŸçš„é…ç½®
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': f'downloads/final_%(title)s.%(ext)s',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'referer': 'https://www.youtube.com/',
                'extractor_args': {
                    'youtube': {
                        'skip': ['dash'],
                        'player_skip': ['js'],
                        'player_client': ['web', 'android'],
                    }
                },
                'cookiesfrombrowser': ('firefox', None, None, None),
                'http_headers': {
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Encoding': 'gzip, deflate',
                    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
                    'Connection': 'keep-alive',
                },
                'no_warnings': True,
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                self.log("ğŸ“‹ è·å–è§†é¢‘ä¿¡æ¯...")
                info = ydl.extract_info(youtube_url, download=False)
                video_title = info.get('title', 'Unknown Title')
                
                self.log(f"âœ… è§†é¢‘æ ‡é¢˜: {video_title}")
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„è§†é¢‘æ ‡é¢˜
                with sqlite3.connect(self.db.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                    conn.commit()
                
                self.log("â¬‡ï¸ å¼€å§‹ä¸‹è½½...")
                ydl.download([youtube_url])
                
                # æ‰¾åˆ°ä¸‹è½½çš„æ–‡ä»¶
                safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                audio_file = f"downloads/final_{safe_title}.mp3"
                
                if os.path.exists(audio_file):
                    self.log(f"ğŸ‰ ä¸‹è½½æˆåŠŸ: {audio_file}")
                    return audio_file, video_title
                else:
                    # å°è¯•å¯»æ‰¾å…¶ä»–å¯èƒ½çš„æ–‡ä»¶å
                    for prefix in ['final_', '']:
                        for ext in ['.mp3', '.m4a', '.webm', '.mp4']:
                            test_file = f"downloads/{prefix}{safe_title}{ext}"
                            if os.path.exists(test_file):
                                return test_file, video_title
                    
                    raise Exception("æ‰¾ä¸åˆ°ä¸‹è½½çš„æ–‡ä»¶")
                
        except Exception as e:
            raise Exception(f"æœ€ç»ˆå¤‡ç”¨æ–¹æ¡ˆå¤±è´¥: {str(e)}")

    def download_audio_ultra_simple(self, youtube_url, video_id):
        """ç»ˆæç®€åŒ–æ–¹æ¡ˆ - æœ€åŸºæœ¬çš„é…ç½®"""
        try:
            print("ä½¿ç”¨ç»ˆæç®€åŒ–é…ç½®...")
            
            # æœ€ç®€å•çš„é…ç½®ï¼Œåªä¸‹è½½ä¸è½¬æ¢
            ydl_opts = {
                'outtmpl': f'downloads/ultra_%(title)s.%(ext)s',
                'format': 'worst',
                'quiet': False,
            }
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                print("è·å–è§†é¢‘ä¿¡æ¯...")
                info = ydl.extract_info(youtube_url, download=False)
                video_title = info.get('title', 'Unknown Title')
                
                print(f"è§†é¢‘æ ‡é¢˜: {video_title}")
                
                # æ›´æ–°æ•°æ®åº“
                with sqlite3.connect(self.db.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                    conn.commit()
                
                print("å¼€å§‹ä¸‹è½½ (ä¸è½¬æ¢æ ¼å¼)...")
                ydl.download([youtube_url])
                
                # æŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
                safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                
                # æŸ¥æ‰¾å¯èƒ½çš„æ–‡ä»¶
                import glob
                pattern = f"downloads/ultra_{safe_title}.*"
                files = glob.glob(pattern)
                
                if files:
                    audio_file = files[0]  # ä½¿ç”¨ç¬¬ä¸€ä¸ªåŒ¹é…çš„æ–‡ä»¶
                    print(f"æ‰¾åˆ°æ–‡ä»¶: {audio_file}")
                    return audio_file, video_title
                else:
                    # åˆ—å‡ºdownloadsç›®å½•çš„æ‰€æœ‰æ–‡ä»¶
                    import os
                    if os.path.exists('downloads'):
                        all_files = os.listdir('downloads')
                        ultra_files = [f for f in all_files if f.startswith('ultra_')]
                        if ultra_files:
                            audio_file = f"downloads/{ultra_files[0]}"
                            return audio_file, video_title
                    
                    raise Exception("æ‰¾ä¸åˆ°ä¸‹è½½çš„æ–‡ä»¶")
                
        except Exception as e:
            raise Exception(f"ç»ˆæç®€åŒ–æ–¹æ¡ˆä¹Ÿå¤±è´¥: {str(e)}")

    def download_audio(self, youtube_url, video_id):
        """ä¸‹è½½YouTubeéŸ³é¢‘ - ä½¿ç”¨è§†é¢‘IDä½œä¸ºæ–‡ä»¶å"""
        try:
            self.clear_logs()  # æ¸…é™¤ä¹‹å‰çš„æ—¥å¿—
            
            # æå–YouTubeè§†é¢‘ID
            try:
                yt_video_id = self.extract_video_id(youtube_url)
                self.log(f"âœ… æå–è§†é¢‘ID: {yt_video_id}")
            except ValueError as e:
                self.log(f"âŒ {str(e)}")
                raise
            
            # æ£€æŸ¥MP3æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            expected_mp3 = f"downloads/{yt_video_id}.mp3"
            if os.path.exists(expected_mp3):
                file_size = os.path.getsize(expected_mp3) / (1024 * 1024)  # MB
                self.log(f"ğŸ‰ å‘ç°å·²å­˜åœ¨çš„MP3æ–‡ä»¶: {expected_mp3} ({file_size:.2f} MB)")
                self.log("â­ï¸ è·³è¿‡ä¸‹è½½ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ–‡ä»¶")
                
                # ä»æ•°æ®åº“è·å–è§†é¢‘æ ‡é¢˜ï¼Œå¦‚æœæ²¡æœ‰åˆ™å°è¯•è·å–
                with sqlite3.connect(self.db.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute('SELECT video_title FROM videos WHERE id=?', (video_id,))
                    result = cursor.fetchone()
                    video_title = result[0] if result and result[0] else None
                
                # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰æ ‡é¢˜ï¼Œåˆ™è·å–è§†é¢‘ä¿¡æ¯
                if not video_title:
                    self.log("ğŸ“‹ è·å–è§†é¢‘æ ‡é¢˜ä¿¡æ¯...")
                    ydl_opts = {'quiet': True}
                    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                        info = ydl.extract_info(youtube_url, download=False)
                        video_title = info.get('title', 'Unknown Title')
                        # æ›´æ–°æ•°æ®åº“ä¸­çš„è§†é¢‘æ ‡é¢˜
                        with sqlite3.connect(self.db.db_path) as conn:
                            cursor = conn.cursor()
                            cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                            conn.commit()
                        self.log(f"âœ… è§†é¢‘æ ‡é¢˜: {video_title}")
                
                return expected_mp3, video_title
            
            self.log("="*60)
            self.log("ğŸ¯ å¼€å§‹YouTubeä¸‹è½½è¿‡ç¨‹")
            self.log(f"ğŸ“¹ URL: {youtube_url}")
            self.log(f"ğŸ†” æ•°æ®åº“ID: {video_id}")
            self.log(f"ğŸ¬ YouTubeè§†é¢‘ID: {yt_video_id}")
            self.log("ğŸ”§ ç­–ç•¥: ä½¿ç”¨è§†é¢‘IDä½œä¸ºæ–‡ä»¶å")
            self.log("="*60)
            
            # ä½¿ç”¨è§†é¢‘IDä½œä¸ºæ–‡ä»¶åçš„é…ç½®
            ydl_opts = {
                'format': 'bestaudio/best',
                'outtmpl': f'downloads/{yt_video_id}.%(ext)s',
                'postprocessors': [{
                    'key': 'FFmpegExtractAudio',
                    'preferredcodec': 'mp3',
                    'preferredquality': '192',
                }],
                'user_agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
                'referer': 'https://www.youtube.com/',
                'extractor_args': {
                    'youtube': {
                        'skip': ['dash'],
                        'player_skip': ['js'],
                        'player_client': ['web', 'android'],
                    }
                },
                'http_headers': {
                    'Accept-Language': 'en-US,en;q=0.9',
                    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',
                    'Accept-Encoding': 'gzip, deflate',
                    'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',
                    'Connection': 'keep-alive',
                },
                'no_warnings': True,
            }
            
            # æ·»åŠ è¯¦ç»†çš„ç¯å¢ƒå’Œé…ç½®æ—¥å¿—
            self.log(f"ğŸ“± Flaskè¿›ç¨‹ç¯å¢ƒä¿¡æ¯:")
            self.log(f"   ğŸ Pythonæ‰§è¡Œè·¯å¾„: {sys.executable}")
            self.log(f"   ğŸ“‚ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
            self.log(f"   ğŸ“¦ yt-dlpç‰ˆæœ¬: {yt_dlp.version.__version__}")
            
            self.log(f"ğŸ”§ yt-dlpé…ç½®:")
            self.log(f"   ğŸµ æ ¼å¼: {ydl_opts['format']}")
            self.log(f"   ğŸ•·ï¸ User-Agent: {ydl_opts['user_agent'][:50]}...")
            self.log(f"   ğŸ”— Referer: {ydl_opts.get('referer', 'æœªè®¾ç½®')}")
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                self.log("ğŸ“‹ å¼€å§‹è·å–è§†é¢‘ä¿¡æ¯...")
                info = ydl.extract_info(youtube_url, download=False)
                video_title = info.get('title', 'Unknown Title')
                
                self.log(f"âœ… è§†é¢‘æ ‡é¢˜: {video_title}")
                self.log(f"âœ… è§†é¢‘æ—¶é•¿: {info.get('duration', 'Unknown')}ç§’")
                self.log(f"âœ… ä¸Šä¼ è€…: {info.get('uploader', 'Unknown')}")
                
                # æ›´æ–°æ•°æ®åº“ä¸­çš„è§†é¢‘æ ‡é¢˜
                with sqlite3.connect(self.db.db_path) as conn:
                    cursor = conn.cursor()
                    cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                    conn.commit()
                
                self.log("â¬‡ï¸ å¼€å§‹ä¸‹è½½...")
                ydl.download([youtube_url])
                
                # ä½¿ç”¨è§†é¢‘IDæŸ¥æ‰¾ä¸‹è½½çš„æ–‡ä»¶
                expected_mp3 = f"downloads/{yt_video_id}.mp3"
                
                # é¦–å…ˆæ£€æŸ¥MP3æ–‡ä»¶ï¼ˆè½¬æ¢åçš„ç›®æ ‡æ ¼å¼ï¼‰
                if os.path.exists(expected_mp3):
                    file_size = os.path.getsize(expected_mp3) / (1024 * 1024)  # MB
                    self.log(f"ğŸ‰ ä¸‹è½½æˆåŠŸ: {expected_mp3} ({file_size:.2f} MB)")
                    return expected_mp3, video_title
                
                # æ£€æŸ¥å…¶ä»–å¯èƒ½çš„æ ¼å¼ï¼ˆæœªè½¬æ¢çš„åŸå§‹æ ¼å¼ï¼‰
                for ext in ['.m4a', '.webm', '.mp4']:
                    test_file = f"downloads/{yt_video_id}{ext}"
                    if os.path.exists(test_file):
                        file_size = os.path.getsize(test_file) / (1024 * 1024)  # MB
                        self.log(f"ğŸ‰ ä¸‹è½½æˆåŠŸ (æ ¼å¼: {ext}): {test_file} ({file_size:.2f} MB)")
                        return test_file, video_title
                
                # å¦‚æœéƒ½æ‰¾ä¸åˆ°ï¼Œåˆ—å‡ºdownloadsç›®å½•å†…å®¹è¿›è¡Œè°ƒè¯•
                self.log("ğŸ” downloadsç›®å½•å†…å®¹:")
                try:
                    for f in os.listdir("downloads"):
                        if f.startswith(yt_video_id):
                            self.log(f"   ğŸ“„ æ‰¾åˆ°ç›¸å…³æ–‡ä»¶: {f}")
                except Exception as e:
                    self.log(f"   âŒ æ— æ³•åˆ—å‡ºç›®å½•: {e}")
                
                raise Exception(f"æ‰¾ä¸åˆ°è§†é¢‘IDä¸º {yt_video_id} çš„ä¸‹è½½æ–‡ä»¶")
                
        except Exception as e:
            self.log("âŒ Androidå®¢æˆ·ç«¯ç­–ç•¥å¤±è´¥!")
            self.log(f"ğŸ” é”™è¯¯è¯¦æƒ…: {str(e)}")
            self.log("\n" + "="*60)
            self.log("ğŸ”„ å°è¯•iOSå®¢æˆ·ç«¯å¤‡ç”¨ç­–ç•¥")
            self.log("="*60)
            
            try:
                # å°è¯•iOSå®¢æˆ·ç«¯
                self.log("ğŸ“± ä½¿ç”¨iOSå®¢æˆ·ç«¯é…ç½®...")
                ios_opts = {
                    'format': 'bestaudio/best',
                    'outtmpl': f'downloads/%(title)s.%(ext)s',
                    'postprocessors': [{
                        'key': 'FFmpegExtractAudio',
                        'preferredcodec': 'mp3',
                        'preferredquality': '192',
                    }],
                    'extractor_args': {'youtube': {'player_client': ['ios']}},
                    'user_agent': 'com.google.ios.youtube/17.31.4 (iPhone; CPU iPhone OS 15_6 like Mac OS X)',
                    'no_warnings': True,
                }
                
                with yt_dlp.YoutubeDL(ios_opts) as ydl:
                    info = ydl.extract_info(youtube_url, download=False)
                    video_title = info.get('title', 'Unknown Title')
                    self.log(f"âœ… iOSç­–ç•¥è·å–æ ‡é¢˜: {video_title}")
                    
                    # æ›´æ–°æ•°æ®åº“
                    with sqlite3.connect(self.db.db_path) as conn:
                        cursor = conn.cursor()
                        cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                        conn.commit()
                    
                    ydl.download([youtube_url])
                    
                    # æŸ¥æ‰¾æ–‡ä»¶
                    safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                    for ext in ['.mp3', '.m4a', '.webm', '.mp4']:
                        audio_file = f"downloads/{safe_title}{ext}"
                        if os.path.exists(audio_file):
                            self.log(f"ğŸ‰ iOSç­–ç•¥æˆåŠŸ: {audio_file}")
                            return audio_file, video_title
                    
                    raise Exception("iOSç­–ç•¥ä¸‹è½½å®Œæˆä½†æ‰¾ä¸åˆ°æ–‡ä»¶")
                    
            except Exception as ios_error:
                self.log("âŒ iOSç­–ç•¥ä¹Ÿå¤±è´¥!")
                self.log(f"ğŸ” é”™è¯¯è¯¦æƒ…: {str(ios_error)}")
                
                # æœ€ç®€åŒ–ç­–ç•¥ - åªä¸‹è½½ä¸è½¬æ¢
                self.log("\nğŸš€ å°è¯•æœ€ç®€åŒ–ç­–ç•¥ (ä¸è½¬æ¢æ ¼å¼)...")
                try:
                    simple_opts = {
                        'format': 'worst[ext=webm]/worst',
                        'outtmpl': f'downloads/%(title)s.%(ext)s',
                        'no_warnings': True,
                    }
                    
                    with yt_dlp.YoutubeDL(simple_opts) as ydl:
                        info = ydl.extract_info(youtube_url, download=False)
                        video_title = info.get('title', 'Unknown Title')
                        self.log(f"âœ… æœ€ç®€ç­–ç•¥è·å–æ ‡é¢˜: {video_title}")
                        
                        # æ›´æ–°æ•°æ®åº“
                        with sqlite3.connect(self.db.db_path) as conn:
                            cursor = conn.cursor()
                            cursor.execute('UPDATE videos SET video_title=? WHERE id=?', (video_title, video_id))
                            conn.commit()
                        
                        ydl.download([youtube_url])
                        
                        # æŸ¥æ‰¾ä»»æ„æ ¼å¼çš„æ–‡ä»¶
                        safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
                        for ext in ['.webm', '.mp4', '.m4a', '.mp3']:
                            audio_file = f"downloads/{safe_title}{ext}"
                            if os.path.exists(audio_file):
                                self.log(f"ğŸ‰ æœ€ç®€ç­–ç•¥æˆåŠŸ: {audio_file}")
                                return audio_file, video_title
                        
                        raise Exception("æœ€ç®€ç­–ç•¥ä¸‹è½½å®Œæˆä½†æ‰¾ä¸åˆ°æ–‡ä»¶")
                        
                except Exception as simple_error:
                    self.log("âŒ æ‰€æœ‰ç­–ç•¥éƒ½å¤±è´¥äº†!")
                    
                    # è·å–å®Œæ•´çš„æ—¥å¿—ä¿¡æ¯
                    detailed_logs = self.get_logs()
                    error_summary = f"""æ‰€æœ‰ä¸‹è½½ç­–ç•¥éƒ½å¤±è´¥äº†ï¼

è¯¦ç»†æ—¥å¿—:
{detailed_logs}

é”™è¯¯æ±‡æ€»:
1ï¸âƒ£ Androidç­–ç•¥: {str(e)}
2ï¸âƒ£ iOSç­–ç•¥: {str(ios_error)}
3ï¸âƒ£ æœ€ç®€ç­–ç•¥: {str(simple_error)}"""
                    raise Exception(error_summary)
    
    def transcribe_audio(self, audio_file, force_retranscribe=False):
        """ä½¿ç”¨Whisperè½¬å½•éŸ³é¢‘"""
        try:
            # æ£€æŸ¥è½¬å½•æ–‡ä»¶æ˜¯å¦å·²å­˜åœ¨
            base_name = os.path.splitext(os.path.basename(audio_file))[0]
            srt_file = f"transcripts/{base_name}.srt"
            transcript_file = f"transcripts/{base_name}.txt"
            
            if not force_retranscribe and os.path.exists(srt_file) and os.path.exists(transcript_file):
                self.log(f"ğŸ‰ å‘ç°å·²å­˜åœ¨çš„è½¬å½•æ–‡ä»¶: {srt_file}")
                self.log("â­ï¸ è·³è¿‡è½¬å½•ï¼Œç›´æ¥ä½¿ç”¨ç°æœ‰æ–‡ä»¶")
                
                # è¯»å–ç°æœ‰çš„è½¬å½•æ–‡æœ¬
                with open(transcript_file, 'r', encoding='utf-8') as f:
                    transcript_text = f.read()
                
                # è§£æSRTæ–‡ä»¶è·å–segmentsä¿¡æ¯ï¼Œå¹¶åˆå¹¶çŸ­ç‰‡æ®µ
                raw_segments = self.parse_srt_file(srt_file)
                merged_segments = self.merge_short_segments(raw_segments)
                
                self.log(f"ğŸ“Š åŸå§‹ç‰‡æ®µæ•°: {len(raw_segments)}, åˆå¹¶åç‰‡æ®µæ•°: {len(merged_segments)}")
                
                return transcript_text, srt_file, merged_segments
            
            if force_retranscribe:
                self.log(f"ğŸ”„ å¼ºåˆ¶é‡æ–°è½¬å½• (ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹)")
            elif os.path.exists(srt_file) or os.path.exists(transcript_file):
                self.log(f"ğŸ”„ è¦†ç›–ç°æœ‰è½¬å½•æ–‡ä»¶ (æ¨¡å‹å‡çº§)")
            
            model = self.load_whisper_model()
            self.log(f"ğŸ™ï¸ å¼€å§‹è½¬å½•éŸ³é¢‘æ–‡ä»¶: {audio_file}")
            
            # ä¼˜åŒ–çš„è½¬å½•å‚æ•° - æ·»åŠ æ›´å¥½çš„åˆ†æ®µæ§åˆ¶
            transcribe_options = {
                'language': 'zh',  # æ˜ç¡®æŒ‡å®šä¸­æ–‡ï¼Œé¿å…è¯­è¨€æ£€æµ‹æ—¶é—´
                'fp16': False,     # CPUä¸‹å…³é—­fp16
                'task': 'transcribe',  # æ˜ç¡®æŒ‡å®šä»»åŠ¡ç±»å‹
                'verbose': False,  # å‡å°‘å†—ä½™è¾“å‡º
                'word_timestamps': True,  # å¯ç”¨è¯çº§æ—¶é—´æˆ³ï¼Œæœ‰åŠ©äºæ›´å¥½çš„åˆ†æ®µ
                'condition_on_previous_text': True,  # åŸºäºå‰æ–‡ä¸Šä¸‹æ–‡ï¼Œæé«˜è¿è´¯æ€§
            }
            
            # å¦‚æœæ˜¯GPUï¼Œå¯ç”¨ä¸€äº›ä¼˜åŒ–é€‰é¡¹
            import torch
            if torch.cuda.is_available():
                transcribe_options['fp16'] = True  # GPUä¸‹å¯ç”¨fp16åŠ é€Ÿ
                print("ğŸš€ ä½¿ç”¨GPUåŠ é€Ÿè½¬å½•...")
            else:
                print("ğŸ’» ä½¿ç”¨CPUè½¬å½•...")
            
            result = model.transcribe(audio_file, **transcribe_options)
            original_segments = result.get('segments', [])
            print(f"âœ… è½¬å½•å®Œæˆï¼Œè¯†åˆ«åˆ° {len(original_segments)} ä¸ªåŸå§‹è¯­éŸ³ç‰‡æ®µ")
            
            # åˆå¹¶çŸ­ç‰‡æ®µä»¥å‡å°‘ç‰‡æ®µæ•°é‡
            merged_segments = self.merge_short_segments(original_segments)
            print(f"ğŸ“Š åˆå¹¶çŸ­ç‰‡æ®µå: {len(merged_segments)} ä¸ªç‰‡æ®µ")
            
            # ç”ŸæˆSRTæ ¼å¼å­—å¹•ï¼ˆä½¿ç”¨åˆå¹¶åçš„ç‰‡æ®µï¼‰
            srt_content = self.generate_srt(merged_segments)
            
            # ç¡®ä¿transcriptsç›®å½•å­˜åœ¨
            os.makedirs('transcripts', exist_ok=True)
            
            # ä¿å­˜SRTæ–‡ä»¶
            with open(srt_file, 'w', encoding='utf-8') as f:
                f.write(srt_content)
            
            # ä¿å­˜çº¯æ–‡æœ¬è½¬å½•
            with open(transcript_file, 'w', encoding='utf-8') as f:
                f.write(result['text'])
            
            print(f"âœ… è½¬å½•å®Œæˆï¼Œä¿å­˜åˆ°: {srt_file}")
            
            return result['text'], srt_file, merged_segments
            
        except Exception as e:
            raise Exception(f"è¯­éŸ³è½¬å½•å¤±è´¥: {str(e)}")
    
    def merge_short_segments(self, segments, target_duration=30.0, max_duration=60.0):
        """
        åˆå¹¶çŸ­ç‰‡æ®µä»¥å‡å°‘ç‰‡æ®µæ•°é‡ï¼Œæé«˜åˆ†ææ•ˆç‡
        ä¿ç•™åŸå§‹ç‰‡æ®µä¿¡æ¯ä»¥ä¾¿æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³åŒ¹é…
        
        Args:
            segments: åŸå§‹ç‰‡æ®µåˆ—è¡¨
            target_duration: ç›®æ ‡ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
            max_duration: æœ€å¤§ç‰‡æ®µæ—¶é•¿ï¼ˆç§’ï¼‰
        """
        if not segments:
            return segments
        
        merged_segments = []
        current_segment = None
        current_original_segments = []  # è®°å½•åˆå¹¶çš„åŸå§‹ç‰‡æ®µ
        
        for segment in segments:
            # ç¡®ä¿segmentæœ‰æ­£ç¡®çš„å­—æ®µ
            if not isinstance(segment, dict):
                continue
                
            start = segment.get('start', 0)
            end = segment.get('end', 0)
            text = segment.get('text', '').strip()
            
            if not text:  # è·³è¿‡ç©ºæ–‡æœ¬ç‰‡æ®µ
                continue
            
            if current_segment is None:
                # å¼€å§‹æ–°çš„åˆå¹¶ç‰‡æ®µ
                current_segment = {
                    'start': start,
                    'end': end,
                    'text': text,
                    'original_segments': [segment]  # ä¿ç•™åŸå§‹ç‰‡æ®µä¿¡æ¯
                }
                current_original_segments = [segment]
            else:
                # æ£€æŸ¥æ˜¯å¦åº”è¯¥åˆå¹¶åˆ°å½“å‰ç‰‡æ®µ
                current_duration = current_segment['end'] - current_segment['start']
                gap = start - current_segment['end']
                
                # åˆå¹¶æ¡ä»¶ï¼š
                # 1. å½“å‰ç‰‡æ®µæ—¶é•¿å°äºç›®æ ‡æ—¶é•¿
                # 2. æ—¶é—´é—´éš”ä¸è¶…è¿‡3ç§’ï¼ˆé¿å…åˆå¹¶ä¸ç›¸å…³çš„å†…å®¹ï¼‰
                # 3. åˆå¹¶åä¸è¶…è¿‡æœ€å¤§æ—¶é•¿
                if (current_duration < target_duration and 
                    gap <= 3.0 and 
                    (end - current_segment['start']) <= max_duration):
                    
                    # åˆå¹¶åˆ°å½“å‰ç‰‡æ®µ
                    current_segment['end'] = end
                    current_segment['text'] += ' ' + text
                    current_segment['original_segments'].append(segment)
                    current_original_segments.append(segment)
                else:
                    # ä¿å­˜å½“å‰ç‰‡æ®µï¼Œå¼€å§‹æ–°ç‰‡æ®µ
                    merged_segments.append(current_segment)
                    current_segment = {
                        'start': start,
                        'end': end,
                        'text': text,
                        'original_segments': [segment]
                    }
                    current_original_segments = [segment]
        
        # æ·»åŠ æœ€åä¸€ä¸ªç‰‡æ®µ
        if current_segment is not None:
            merged_segments.append(current_segment)
        
        return merged_segments

    def parse_srt_file(self, srt_file):
        """è§£æSRTæ–‡ä»¶è·å–segmentsä¿¡æ¯"""
        segments = []
        try:
            with open(srt_file, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # ç®€å•çš„SRTè§£æ
            blocks = content.strip().split('\n\n')
            for block in blocks:
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # è§£ææ—¶é—´æˆ³
                    time_line = lines[1]
                    if ' --> ' in time_line:
                        start_str, end_str = time_line.split(' --> ')
                        start_seconds = self.srt_time_to_seconds(start_str)
                        end_seconds = self.srt_time_to_seconds(end_str)
                        
                        # åˆå¹¶æ–‡æœ¬è¡Œ
                        text = ' '.join(lines[2:])
                        
                        segments.append({
                            'start': start_seconds,
                            'end': end_seconds,
                            'text': text
                        })
            
            return segments
        except Exception as e:
            print(f"è§£æSRTæ–‡ä»¶å¤±è´¥: {e}")
            return []
    
    def srt_time_to_seconds(self, time_str):
        """å°†SRTæ—¶é—´æ ¼å¼è½¬æ¢ä¸ºç§’æ•°"""
        try:
            # æ ¼å¼: HH:MM:SS,mmm
            time_part, ms_part = time_str.split(',')
            h, m, s = map(int, time_part.split(':'))
            ms = int(ms_part)
            return h * 3600 + m * 60 + s + ms / 1000.0
        except:
            return 0
    
    def generate_srt(self, segments):
        """ç”ŸæˆSRTæ ¼å¼å­—å¹•"""
        srt_content = ""
        for i, segment in enumerate(segments):
            start_time = self.seconds_to_srt_time(segment['start'])
            end_time = self.seconds_to_srt_time(segment['end'])
            text = segment['text'].strip()
            
            srt_content += f"{i+1}\n"
            srt_content += f"{start_time} --> {end_time}\n"
            srt_content += f"{text}\n\n"
        
        return srt_content
    
    def seconds_to_srt_time(self, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸ºSRTæ—¶é—´æ ¼å¼"""
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        millisecs = int((seconds % 1) * 1000)
        
        return f"{hours:02d}:{minutes:02d}:{secs:02d},{millisecs:03d}"
    
    def analyze_content(self, transcript, segments):
        """ä½¿ç”¨AIåˆ†æå†…å®¹å¹¶ç”Ÿæˆç®€æŠ¥"""
        try:
            # æ›´å‡†ç¡®çš„tokenä¼°ç®— (ä¸­æ–‡: 1å­—ç¬¦ â‰ˆ 1.5 tokens, è‹±æ–‡: 1 token â‰ˆ 4 characters)
            # ä¸ºä¸­æ–‡å†…å®¹ä½¿ç”¨æ›´ä¿å®ˆçš„ä¼°ç®—
            estimated_tokens = len(transcript) * 1.5  # ä¸­æ–‡å­—ç¬¦æ›´å‡†ç¡®çš„tokenä¼°ç®—
            
            # GPT-4çš„å®é™…é™åˆ¶ï¼šè¾“å…¥tokençº¦8192ï¼Œéœ€è¦é¢„ç•™è¾“å‡ºç©ºé—´
            # æç¤ºè¯å¤§çº¦ä½¿ç”¨500-800 tokensï¼Œè¾“å‡ºéœ€è¦é¢„ç•™1000-1500 tokens
            max_input_tokens = 6000  # ä¿å®ˆä¼°è®¡ï¼Œç¡®ä¿ä¸è¶…è¿‡GPT-4é™åˆ¶
            
            self.log(f"ğŸ“Š æ–‡å­—ç¨¿é•¿åº¦: {len(transcript)} å­—ç¬¦")
            self.log(f"ğŸ“Š ä¼°ç®—tokenæ•°: {estimated_tokens:.0f}")
            self.log(f"ğŸ“Š æ¨¡å‹é™åˆ¶: {max_input_tokens} tokens (åŒ…å«æç¤ºè¯)")
            
            if estimated_tokens <= max_input_tokens:
                self.log("ğŸ“ æ–‡æœ¬é•¿åº¦é€‚ä¸­ï¼Œä½¿ç”¨å•æ¬¡åˆ†æ")
                return self._analyze_single_chunk(transcript, segments)
            else:
                self.log("ğŸ“ æ–‡æœ¬è¿‡é•¿ï¼Œä½¿ç”¨åˆ†æ®µåˆ†æ")
                return self._analyze_multiple_chunks(transcript, segments, max_input_tokens)
            
        except Exception as e:
            raise Exception(f"å†…å®¹åˆ†æå¤±è´¥: {str(e)}")

    def _analyze_single_chunk(self, transcript, segments):
        """åˆ†æå•ä¸ªæ–‡æœ¬å—"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹YouTubeè§†é¢‘çš„æ–‡å­—ç¨¿ï¼Œå¹¶ç”Ÿæˆä¸€ä»½ç®€æŠ¥ï¼š

æ–‡å­—ç¨¿å†…å®¹ï¼š
{transcript}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
{{
    "summary": "è§†é¢‘ä¸»è¦å†…å®¹çš„ç®€æ´æ€»ç»“ï¼ˆ3-5å¥è¯ï¼‰",
    "key_points": [
        {{
            "point": "è¦ç‚¹æè¿°",
            "explanation": "è¯¦ç»†è§£é‡Š",
            "timestamp": "èµ·å§‹æ—¶é—´ï¼ˆç§’ï¼‰",
            "quote": "åŸæ–‡å¼•ç”¨ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"
        }}
    ]
}}

è¦æ±‚ï¼š
1. æå–3-8ä¸ªå…³é”®è¦ç‚¹
2. æ¯ä¸ªè¦ç‚¹éƒ½è¦åŒ…å«å¯¹åº”çš„æ—¶é—´æˆ³
3. è¦ç‚¹åº”è¯¥æ¶µç›–è§†é¢‘çš„ä¸»è¦è§‚ç‚¹å’Œé‡è¦ä¿¡æ¯
4. æ—¶é—´æˆ³è¦å‡†ç¡®å¯¹åº”åˆ°ç›¸å…³å†…å®¹
"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",  # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„æ¨¡å‹åç§°
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1500  # é™åˆ¶è¾“å‡ºtokenæ•°é‡
            )
        except Exception as e:
            # å¦‚æœé‡åˆ°tokené™åˆ¶é”™è¯¯ï¼Œå°è¯•ä½¿ç”¨æ›´å¤§å®¹é‡çš„æ¨¡å‹
            if "token" in str(e).lower() or "context" in str(e).lower():
                self.log(f"âš ï¸ GPT-4 tokené™åˆ¶ï¼Œå°è¯•ä½¿ç”¨gpt-4-turbo...")
                try:
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4-turbo",
                        messages=[{"role": "user", "content": prompt}],
                        temperature=0.3,
                        max_tokens=1500
                    )
                except Exception as e2:
                    # å¦‚æœè¿˜æ˜¯å¤±è´¥ï¼Œå°è¯•ç¼©çŸ­æ–‡æœ¬
                    self.log(f"âš ï¸ gpt-4-turboä¹Ÿå¤±è´¥ï¼Œç¼©çŸ­æ–‡æœ¬é‡è¯•...")
                    shortened_transcript = transcript[:4000]  # æˆªå–å‰4000å­—ç¬¦
                    shortened_prompt = prompt.replace(transcript, shortened_transcript)
                    response = self.openai_client.chat.completions.create(
                        model="gpt-4",
                        messages=[{"role": "user", "content": shortened_prompt}],
                        temperature=0.3,
                        max_tokens=1500
                    )
            else:
                raise e
        
        return json.loads(response.choices[0].message.content)

    def _analyze_multiple_chunks(self, transcript, segments, max_input_tokens):
        """åˆ†æ®µåˆ†æé•¿æ–‡æœ¬"""
        # è½¬æ¢tokené™åˆ¶ä¸ºå­—ç¬¦æ•°ï¼ˆä¸­æ–‡å­—ç¬¦ï¼‰
        # ä¸ºåˆ†æ®µé¢„ç•™ä¸€äº›tokenç©ºé—´ç»™æç¤ºè¯
        prompt_tokens = 500  # é¢„ç•™ç»™æç¤ºè¯çš„token
        available_tokens = max_input_tokens - prompt_tokens
        chunk_size_chars = int(available_tokens / 1.5)  # è½¬æ¢ä¸ºä¸­æ–‡å­—ç¬¦æ•°
        
        chunks = []
        
        # æ™ºèƒ½åˆ†å‰²ï¼šå…ˆå°è¯•å¥å­è¾¹ç•Œï¼Œå¦‚æœæ²¡æœ‰åˆ™æŒ‰å­—ç¬¦æ•°å¼ºåˆ¶åˆ†å‰²
        # å°è¯•ä¸åŒçš„åˆ†å‰²æ–¹æ³•
        potential_delimiters = ['ã€‚', 'ï¼', 'ï¼Ÿ', '\n', ' ']
        best_sentences = None
        
        for delimiter in potential_delimiters:
            test_sentences = transcript.split(delimiter)
            if len(test_sentences) > 1:  # æ‰¾åˆ°æœ‰æ•ˆåˆ†å‰²
                best_sentences = test_sentences
                best_delimiter = delimiter
                break
        
        if best_sentences is None or len(best_sentences) == 1:
            # æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åˆ†éš”ç¬¦ï¼ŒæŒ‰å­—ç¬¦æ•°å¼ºåˆ¶åˆ†å‰²
            best_sentences = []
            for i in range(0, len(transcript), chunk_size_chars):
                chunk = transcript[i:i + chunk_size_chars]
                best_sentences.append(chunk)
            best_delimiter = ""
        
        current_chunk = ""
        current_segments = []
        
        for i, sentence in enumerate(best_sentences):
            # é‡æ–°åŠ ä¸Šåˆ†éš”ç¬¦ï¼ˆé™¤äº†æœ€åä¸€å¥å’Œå¼ºåˆ¶åˆ†å‰²çš„æƒ…å†µï¼‰
            if best_delimiter and i < len(best_sentences) - 1:
                sentence_with_delimiter = sentence + best_delimiter
            else:
                sentence_with_delimiter = sentence
            
            # æ£€æŸ¥æ·»åŠ è¿™ä¸ªå¥å­æ˜¯å¦ä¼šè¶…è¿‡é™åˆ¶
            if len(current_chunk + sentence_with_delimiter) <= chunk_size_chars or not current_chunk:
                current_chunk += sentence_with_delimiter
                # æ‰¾åˆ°å¯¹åº”çš„segments
                chunk_segments = [s for s in segments if sentence[:20] in s.get('text', '')]
                current_segments.extend(chunk_segments)
            else:
                # å½“å‰å¥å­ä¼šå¯¼è‡´è¶…é™ï¼Œä¿å­˜å½“å‰å—å¹¶å¼€å§‹æ–°å—
                if current_chunk:  # ç¡®ä¿ä¸ä¿å­˜ç©ºå—
                    chunks.append((current_chunk, current_segments))
                
                # æ£€æŸ¥å•ä¸ªå¥å­æ˜¯å¦å¤ªé•¿
                if len(sentence_with_delimiter) > chunk_size_chars:
                    # å¥å­å¤ªé•¿ï¼ŒæŒ‰å­—ç¬¦æ•°å¼ºåˆ¶åˆ†å‰²
                    for j in range(0, len(sentence_with_delimiter), chunk_size_chars):
                        sub_chunk = sentence_with_delimiter[j:j + chunk_size_chars]
                        if sub_chunk:
                            chunks.append((sub_chunk, []))
                    current_chunk = ""
                    current_segments = []
                else:
                    current_chunk = sentence_with_delimiter
                    current_segments = [s for s in segments if sentence[:20] in s.get('text', '')]
        
        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk:
            chunks.append((current_chunk, current_segments))
        
        self.log(f"ğŸ“ åˆ†å‰²æˆ {len(chunks)} ä¸ªæ–‡æœ¬å—è¿›è¡Œåˆ†æ")
        self.log(f"ğŸ“ æ¯å—æœ€å¤§å­—ç¬¦æ•°: {chunk_size_chars}")
        
        # åˆ†ææ¯ä¸ªchunk
        all_summaries = []
        all_key_points = []
        
        for i, (chunk_text, chunk_segments) in enumerate(chunks):
            chunk_char_count = len(chunk_text)
            estimated_chunk_tokens = chunk_char_count * 1.5
            self.log(f"ğŸ“Š åˆ†æç¬¬ {i+1}/{len(chunks)} ä¸ªæ–‡æœ¬å— ({chunk_char_count}å­—ç¬¦, ~{estimated_chunk_tokens:.0f}tokens)...")
            
            try:
                chunk_analysis = self._analyze_chunk_with_context(chunk_text, i+1, len(chunks))
                
                if 'summary' in chunk_analysis:
                    all_summaries.append(chunk_analysis['summary'])
                if 'key_points' in chunk_analysis:
                    # è°ƒæ•´æ—¶é—´æˆ³ä¸ºåŸè§†é¢‘çš„ç›¸å¯¹æ—¶é—´
                    adjusted_points = []
                    for point in chunk_analysis['key_points']:
                        # åœ¨åŸsegmentsä¸­æ‰¾åˆ°åŒ¹é…çš„æ—¶é—´æˆ³
                        matching_segment = self._find_matching_segment(point.get('quote', ''), segments)
                        if matching_segment:
                            point['timestamp'] = matching_segment['start']
                        adjusted_points.append(point)
                    all_key_points.extend(adjusted_points)
            except Exception as e:
                self.log(f"âš ï¸ ç¬¬{i+1}å—åˆ†æå¤±è´¥: {str(e)}")
                # ç»§ç»­å¤„ç†å…¶ä»–å—
                continue
        
        # åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ
        self.log("ğŸ“Š åˆå¹¶åˆ†æç»“æœ...")
        final_summary = self._merge_summaries(all_summaries)
        final_key_points = self._merge_key_points(all_key_points)
        
        return {
            'summary': final_summary,
            'key_points': final_key_points
        }

    def _analyze_chunk_with_context(self, chunk_text, chunk_index, total_chunks):
        """åˆ†æå•ä¸ªæ–‡æœ¬å—ï¼ˆå¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼‰"""
        prompt = f"""
è¯·åˆ†æä»¥ä¸‹YouTubeè§†é¢‘çš„éƒ¨åˆ†æ–‡å­—ç¨¿ï¼ˆç¬¬{chunk_index}éƒ¨åˆ†ï¼Œå…±{total_chunks}éƒ¨åˆ†ï¼‰ï¼š

æ–‡å­—ç¨¿å†…å®¹ï¼š
{chunk_text}

è¯·æŒ‰ä»¥ä¸‹æ ¼å¼è¾“å‡ºJSONï¼š
{{
    "summary": "è¿™éƒ¨åˆ†å†…å®¹çš„ç®€æ´æ€»ç»“ï¼ˆ2-3å¥è¯ï¼‰",
    "key_points": [
        {{
            "point": "è¦ç‚¹æè¿°",
            "explanation": "è¯¦ç»†è§£é‡Š",
            "timestamp": "0",
            "quote": "åŸæ–‡å¼•ç”¨ï¼ˆå¦‚æœæœ‰çš„è¯ï¼‰"
        }}
    ]
}}

è¦æ±‚ï¼š
1. æå–2-4ä¸ªå…³é”®è¦ç‚¹
2. é‡ç‚¹å…³æ³¨è¿™éƒ¨åˆ†çš„ä¸»è¦è§‚ç‚¹
3. æä¾›åŸæ–‡å¼•ç”¨ä»¥ä¾¿åç»­åŒ¹é…æ—¶é—´æˆ³
"""

        try:
            response = self.openai_client.chat.completions.create(
                model="gpt-4",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1200  # åˆ†å—åˆ†æä½¿ç”¨è¾ƒå°‘çš„è¾“å‡ºtoken
            )
        except Exception as e:
            if "token" in str(e).lower() or "context" in str(e).lower():
                # å¦‚æœchunkä»ç„¶å¤ªå¤§ï¼Œè¿›ä¸€æ­¥ç¼©çŸ­
                shortened_chunk = chunk_text[:2000]
                shortened_prompt = prompt.replace(chunk_text, shortened_chunk)
                response = self.openai_client.chat.completions.create(
                    model="gpt-4",
                    messages=[{"role": "user", "content": shortened_prompt}],
                    temperature=0.3,
                    max_tokens=1200
                )
            else:
                raise e
        
        return json.loads(response.choices[0].message.content)

    def _find_matching_segment(self, quote_text, segments):
        """åœ¨segmentsä¸­æ‰¾åˆ°åŒ¹é…çš„æ–‡æœ¬ç‰‡æ®µï¼Œä½¿ç”¨æ”¹è¿›çš„åŒ¹é…ç®—æ³•"""
        if not quote_text or not segments:
            return None
        
        # æ¸…ç†å¼•ç”¨æ–‡æœ¬
        quote_clean = self._clean_text_for_matching(quote_text)
        if not quote_clean:
            return None
        
        best_match = None
        best_score = 0
        
        for segment in segments:
            # ä¼˜å…ˆåœ¨åˆå¹¶ç‰‡æ®µçš„åŸå§‹ç‰‡æ®µä¸­æŸ¥æ‰¾æ›´ç²¾ç¡®çš„åŒ¹é…
            if 'original_segments' in segment and segment['original_segments']:
                for orig_segment in segment['original_segments']:
                    orig_clean = self._clean_text_for_matching(orig_segment.get('text', ''))
                    if orig_clean:
                        score = self._calculate_text_similarity(quote_clean, orig_clean)
                        if score > best_score:
                            best_score = score
                            # è¿”å›åŸå§‹ç‰‡æ®µä»¥è·å¾—æ›´ç²¾ç¡®çš„æ—¶é—´æˆ³
                            best_match = orig_segment
            
            # ä¹Ÿæ£€æŸ¥åˆå¹¶åçš„ç‰‡æ®µ
            segment_clean = self._clean_text_for_matching(segment.get('text', ''))
            if segment_clean:
                score = self._calculate_text_similarity(quote_clean, segment_clean)
                if score > best_score:
                    best_score = score
                    best_match = segment
        
        # åªæœ‰å½“åŒ¹é…åˆ†æ•°è¶³å¤Ÿé«˜æ—¶æ‰è¿”å›åŒ¹é…ç»“æœ
        if best_score >= 0.3:  # 30%çš„ç›¸ä¼¼åº¦é˜ˆå€¼
            self.log(f"ğŸ¯ æ—¶é—´æˆ³åŒ¹é…: æ‰¾åˆ°{best_score:.2f}ç›¸ä¼¼åº¦åŒ¹é…")
            return best_match
        
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¥½çš„åŒ¹é…ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
        partial_match = self._find_partial_match(quote_clean, segments)
        if partial_match:
            self.log(f"âš ï¸ æ—¶é—´æˆ³åŒ¹é…: ä½¿ç”¨éƒ¨åˆ†åŒ¹é…")
            return partial_match
        
        # æœ€åçš„å›é€€é€‰é¡¹
        if segments:
            self.log(f"âŒ æ—¶é—´æˆ³åŒ¹é…: æœªæ‰¾åˆ°åŒ¹é…ï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç‰‡æ®µ")
            return segments[0]
        
        return None
    
    def _clean_text_for_matching(self, text):
        """æ¸…ç†æ–‡æœ¬ç”¨äºåŒ¹é…"""
        if not text:
            return ""
        
        import re
        # ç§»é™¤æ ‡ç‚¹ç¬¦å·å’Œå¤šä½™ç©ºæ ¼ï¼Œè½¬æ¢ä¸ºå°å†™
        cleaned = re.sub(r'[^\w\s]', '', text.lower())
        cleaned = re.sub(r'\s+', ' ', cleaned).strip()
        return cleaned
    
    def _calculate_text_similarity(self, text1, text2):
        """è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦"""
        if not text1 or not text2:
            return 0
        
        # ä½¿ç”¨ç®€å•çš„è¯æ±‡é‡å ç®—æ³•
        words1 = set(text1.split())
        words2 = set(text2.split())
        
        if not words1 or not words2:
            return 0
        
        # è®¡ç®—Jaccardç›¸ä¼¼åº¦
        intersection = words1 & words2
        union = words1 | words2
        
        if not union:
            return 0
        
        return len(intersection) / len(union)
    
    def _find_partial_match(self, quote_clean, segments):
        """å¯»æ‰¾éƒ¨åˆ†åŒ¹é…çš„æ®µè½"""
        quote_words = quote_clean.split()
        if len(quote_words) < 3:  # å¤ªçŸ­çš„å¼•ç”¨ä¸è¿›è¡Œéƒ¨åˆ†åŒ¹é…
            return segments[0] if segments else None
        
        # å°è¯•åŒ¹é…å‰å‡ ä¸ªè¯æˆ–åå‡ ä¸ªè¯
        for segment in segments:
            segment_clean = self._clean_text_for_matching(segment.get('text', ''))
            segment_words = segment_clean.split()
            
            # æ£€æŸ¥å¼€å¤´å’Œç»“å°¾çš„åŒ¹é…
            if self._has_partial_overlap(quote_words, segment_words):
                return segment
        
        return segments[0] if segments else None
    
    def _has_partial_overlap(self, words1, words2):
        """æ£€æŸ¥ä¸¤ä¸ªè¯æ±‡åˆ—è¡¨æ˜¯å¦æœ‰éƒ¨åˆ†é‡å """
        if len(words1) < 3 or len(words2) < 3:
            return False
        
        # æ£€æŸ¥å¼€å¤´3ä¸ªè¯çš„åŒ¹é…
        start_match = len(set(words1[:3]) & set(words2[:3])) >= 2
        
        # æ£€æŸ¥ç»“å°¾3ä¸ªè¯çš„åŒ¹é…  
        end_match = len(set(words1[-3:]) & set(words2[-3:])) >= 2
        
        return start_match or end_match

    def _merge_summaries(self, summaries):
        """åˆå¹¶å¤šä¸ªæ‘˜è¦"""
        if not summaries:
            return "æ— æ³•ç”Ÿæˆæ‘˜è¦"
        
        # ç®€å•åˆå¹¶ï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ç”¨AIå†æ¬¡æ€»ç»“
        combined = "ã€‚".join(summaries)
        return combined

    def _merge_key_points(self, all_key_points):
        """åˆå¹¶å¹¶å»é‡å…³é”®è¦ç‚¹"""
        # ç®€å•å»é‡å’Œé™åˆ¶æ•°é‡
        seen_points = set()
        merged_points = []
        
        for point in all_key_points:
            point_key = point.get('point', '')
            if point_key not in seen_points and len(merged_points) < 8:
                seen_points.add(point_key)
                merged_points.append(point)
        
        return merged_points
    
    def generate_report_html(self, video_title, youtube_url, analysis, srt_file):
        """ç”ŸæˆHTMLç®€æŠ¥"""
        try:
            html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{video_title} - è§†é¢‘ç®€æŠ¥</title>
    <style>
        body {{ font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
        .header {{ background: #f5f5f5; padding: 20px; border-radius: 8px; margin-bottom: 20px; }}
        .summary {{ background: #e8f4fd; padding: 15px; border-radius: 8px; margin-bottom: 20px; }}
        .key-point {{ background: white; border: 1px solid #ddd; padding: 15px; margin-bottom: 15px; border-radius: 8px; }}
        .timestamp {{ background: #007bff; color: white; padding: 4px 8px; border-radius: 4px; text-decoration: none; }}
        .timestamp:hover {{ background: #0056b3; }}
        .quote {{ font-style: italic; color: #666; margin-top: 10px; }}
    </style>
</head>
<body>
    <div class="header">
        <h1>{video_title}</h1>
        <p><strong>åŸè§†é¢‘é“¾æ¥ï¼š</strong> <a href="{youtube_url}" target="_blank">{youtube_url}</a></p>
        <p><strong>ç”Ÿæˆæ—¶é—´ï¼š</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
    </div>
    
    <div class="summary">
        <h2>ğŸ“‹ å†…å®¹æ‘˜è¦</h2>
        <p>{analysis['summary']}</p>
    </div>
    
    <div class="key-points">
        <h2>ğŸ”‘ å…³é”®è¦ç‚¹</h2>
"""
            
            for i, point in enumerate(analysis['key_points'], 1):
                timestamp_seconds = point.get('timestamp', 0)
                # ç¡®ä¿timestampæ˜¯æ•°å­—ç±»å‹
                try:
                    timestamp_seconds = float(timestamp_seconds) if timestamp_seconds else 0
                except (ValueError, TypeError):
                    timestamp_seconds = 0
                
                timestamp_url = f"{youtube_url}&t={int(timestamp_seconds)}s"
                timestamp_display = self.seconds_to_display_time(timestamp_seconds)
                
                html_content += f"""
        <div class="key-point">
            <h3>{i}. {point['point']}</h3>
            <p>{point['explanation']}</p>
            <p><a href="{timestamp_url}" target="_blank" class="timestamp">â° {timestamp_display}</a></p>
            {f'<div class="quote">"{point["quote"]}"</div>' if point.get('quote') else ''}
        </div>
"""
            
            html_content += """
    </div>
</body>
</html>
"""
            
            # ä¿å­˜HTMLæ–‡ä»¶
            safe_title = "".join(c for c in video_title if c.isalnum() or c in (' ', '-', '_')).rstrip()
            report_filename = f"{safe_title}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.html"
            report_path = f"reports/{report_filename}"
            
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            return report_filename
            
        except Exception as e:
            raise Exception(f"ç”Ÿæˆç®€æŠ¥å¤±è´¥: {str(e)}")
    
    def seconds_to_display_time(self, seconds):
        """å°†ç§’æ•°è½¬æ¢ä¸ºæ˜¾ç¤ºæ ¼å¼"""
        # ç¡®ä¿è¾“å…¥æ˜¯æ•°å­—ç±»å‹
        try:
            seconds = float(seconds) if seconds else 0
        except (ValueError, TypeError):
            seconds = 0
            
        hours = int(seconds // 3600)
        minutes = int((seconds % 3600) // 60)
        secs = int(seconds % 60)
        
        if hours > 0:
            return f"{hours:02d}:{minutes:02d}:{secs:02d}"
        else:
            return f"{minutes:02d}:{secs:02d}"
    
    def process_video(self, video_id, youtube_url):
        """å®Œæ•´çš„è§†é¢‘å¤„ç†æµç¨‹"""
        self.clear_logs()  # æ¸…é™¤ä¹‹å‰çš„æ—¥å¿—
        
        self.log("="*60)
        self.log("ğŸ¬ å¼€å§‹è§†é¢‘å¤„ç†æµç¨‹")
        self.log(f"ğŸ“¹ è§†é¢‘ID: {video_id}")
        self.log(f"ğŸ”— YouTube URL: {youtube_url}")
        self.log("="*60)
        
        try:
            self.log("ğŸ“ æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºprocessing...")
            # æ›´æ–°çŠ¶æ€ä¸ºå¤„ç†ä¸­
            self.db.update_video_status(video_id, 'processing')
            self.log("âœ… æ•°æ®åº“çŠ¶æ€æ›´æ–°å®Œæˆ")
            
            # 1. ä¸‹è½½éŸ³é¢‘
            self.log("1ï¸âƒ£ æ­¥éª¤ä¸€: ä¸‹è½½YouTubeéŸ³é¢‘")
            audio_file, video_title = self.download_audio(youtube_url, video_id)
            self.log(f"âœ… éŸ³é¢‘ä¸‹è½½å®Œæˆ: {audio_file}")
            
            # 2. æ¨¡å‹æ£€æŸ¥å’Œæ™ºèƒ½é‡åˆ†æ
            self.log("2ï¸âƒ£ æ­¥éª¤äºŒ: æ£€æŸ¥Whisperæ¨¡å‹å’Œé‡åˆ†æéœ€æ±‚")
            current_model = self.get_current_optimal_model()
            should_reanalyze, previous_model = self.should_reanalyze_with_better_model(video_id, current_model)
            
            if should_reanalyze:
                self.log(f"ğŸš€ å°†ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹é‡æ–°åˆ†æ")
                self.log(f"ğŸ“Š è´¨é‡æå‡é¢„æœŸ: è½¬å½•å‡†ç¡®åº¦ +10-15%")
                # å¼ºåˆ¶é‡æ–°è½¬å½•
                force_retranscribe = True
            else:
                self.log(f"ğŸ“ ä½¿ç”¨æ¨¡å‹: {current_model}")
                force_retranscribe = False
            
            # 3. è¯­éŸ³è½¬å½•
            self.log("3ï¸âƒ£ æ­¥éª¤ä¸‰: ä½¿ç”¨Whisperè¿›è¡Œè¯­éŸ³è½¬å½•")
            transcript, srt_file, segments = self.transcribe_audio(audio_file, force_retranscribe)
            self.log(f"âœ… è¯­éŸ³è½¬å½•å®Œæˆï¼Œå…±{len(segments)}ä¸ªç‰‡æ®µ")
            
            # æ›´æ–°ä½¿ç”¨çš„æ¨¡å‹è®°å½•
            self.db.update_whisper_model(video_id, current_model)
            
            # 4. AIåˆ†æ
            self.log("4ï¸âƒ£ æ­¥éª¤å››: ä½¿ç”¨GPT-4è¿›è¡Œå†…å®¹åˆ†æ")
            analysis = self.analyze_content(transcript, segments)
            self.log(f"âœ… å†…å®¹åˆ†æå®Œæˆï¼Œæå–{len(analysis.get('key_points', []))}ä¸ªå…³é”®è¦ç‚¹")
            
            # 5. ç”Ÿæˆç®€æŠ¥
            self.log("5ï¸âƒ£ æ­¥éª¤äº”: ç”ŸæˆHTMLç®€æŠ¥")
            report_filename = self.generate_report_html(video_title, youtube_url, analysis, srt_file)
            self.log(f"âœ… HTMLç®€æŠ¥ç”Ÿæˆå®Œæˆ: {report_filename}")
            
            # 6. æ›´æ–°æ•°æ®åº“
            self.log("ğŸ“ æ›´æ–°æ•°æ®åº“è®°å½•...")
            self.db.update_report_filename(video_id, report_filename)
            self.db.update_video_status(video_id, 'completed')
            
            self.log("="*60)
            self.log("ğŸ‰ è§†é¢‘å¤„ç†æµç¨‹å…¨éƒ¨å®Œæˆ!")
            self.log(f"ğŸ“‹ ç®€æŠ¥æ–‡ä»¶: {report_filename}")
            self.log("="*60)
            
        except Exception as e:
            import traceback
            error_msg = str(e)
            detailed_traceback = traceback.format_exc()
            
            print("="*80)
            print("âŒ VIDEO_PROCESSOR: process_videoå¼‚å¸¸!")
            print(f"   ğŸš¨ é”™è¯¯ä¿¡æ¯: {error_msg}")
            print(f"   ğŸ“ è¯¦ç»†å †æ ˆ:")
            print(detailed_traceback)
            print("="*80)
            
            print(f"ğŸ“Š æ›´æ–°æ•°æ®åº“çŠ¶æ€ä¸ºfailed...")
            self.db.update_video_status(video_id, 'failed', error_msg)